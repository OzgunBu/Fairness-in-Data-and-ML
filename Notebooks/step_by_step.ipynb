{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 0.19.1\n",
      "pandas: 0.21.1\n",
      "kerads: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "# HIDE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import keras as ke\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "create_gif = False\n",
    "\n",
    "print(f\"sklearn: {sk.__version__}\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"kerads: {ke.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in your data are:\n",
      "  ['39' ' State-gov' ' 77516' ' Bachelors' ' 13' ' Never-married'\n",
      " ' Adm-clerical' ' Not-in-family' ' White' ' Male' ' 2174' ' 0' ' 40'\n",
      " ' United-States' ' <=50K']\n"
     ]
    }
   ],
   "source": [
    "# reading the file from a path and list the field names and input columns of interest\n",
    "path = 'data/adult.data'\n",
    "\n",
    "\n",
    "def reading_data(path):\n",
    "    your_data_df = pd.read_csv(path)\n",
    "    all_columns = np.array(your_data_df.columns)\n",
    "    print('Columns in your data are:\\n ',all_columns)\n",
    "    all_columns = set(all_columns.tolist())\n",
    "    #print(type(all_columns))\n",
    "    \n",
    "    return your_data_df, all_columns\n",
    "\n",
    "your_data_df, all_columns = reading_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which column is your output (prediction, estimation etc.)?: <=50K\n",
      "Your prediction column is ' <=50K'\n"
     ]
    }
   ],
   "source": [
    "# TODO: use 'input_from_user'\n",
    "valid_input = False\n",
    "while valid_input == False:\n",
    "    answer = input('Which column is your output (prediction, estimation etc.)?:')\n",
    "    if answer not in all_columns:\n",
    "        print('Please enter a valid column')\n",
    "    else:\n",
    "        valid_input = True\n",
    "\n",
    "output_field = answer\n",
    "print(\"Your prediction column is '{}'\".format(output_field))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_from_user(input_str, warn_str, result_str, possible_set):\n",
    "    \n",
    "    valid_input = False\n",
    "    while valid_input == False:\n",
    "        answer = input(input_str)\n",
    "        if answer not in possible_set:\n",
    "            print(warn_str)\n",
    "        else:\n",
    "            valid_input = True\n",
    "    print(result_str+\"'{}'\".format(answer))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your prediction column possible values '{' <=50K', ' >50K'}'\n",
      "Please enter two different labels in the output field: \n",
      "Enter label 0: <=50K\n",
      "Your output label 0 is ' <=50K'\n",
      "Enter label 1: >50K\n",
      "Your output label 1 is ' >50K'\n"
     ]
    }
   ],
   "source": [
    "possible_set = set(your_data_df[output_field].unique())\n",
    "print(\"Your prediction column possible values '{}'\".format(possible_set))\n",
    "print('Please enter two different labels in the output field: ')\n",
    "\n",
    "input_str = 'Enter label 0:'\n",
    "warn_str = 'Please enter a valid lable within output field'\n",
    "result_str = \"Your output label 0 is \"\n",
    "output_label0 = input_from_user(input_str, warn_str, result_str, possible_set)\n",
    "\n",
    "possible_set.remove(output_label0)\n",
    "\n",
    "input_str = 'Enter label 1:'\n",
    "warn_str = 'Please enter a valid lable within output field'\n",
    "result_str = \"Your output label 1 is \"\n",
    "output_label1 = input_from_user(input_str, warn_str, result_str, possible_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which column is your sensitive attribute?: White\n",
      "Your sensitive attribute column is ' White'\n"
     ]
    }
   ],
   "source": [
    "# TODO: use 'input_from_user'\n",
    "valid_input = False\n",
    "while valid_input == False:\n",
    "    answer = input('Which column is your sensitive attribute?:')\n",
    "    if answer not in all_columns or answer == output_field:\n",
    "        print('Please enter a valid column, cannot be the same with prediction column')\n",
    "    else:\n",
    "        valid_input = True\n",
    "\n",
    "sensitive_field = answer\n",
    "print(\"Your sensitive attribute column is '{}'\".format(sensitive_field))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values from the sensitive class:{' Other', ' White', ' Amer-Indian-Eskimo', ' Black', ' Asian-Pac-Islander'}\n",
      "Please enter two different classes in the sensisitve field: \n",
      "Enter class 0: White\n",
      "Your sensitive attribute class 0 is ' White'\n",
      "Enter class 1: Black\n",
      "Your sensitive attribute class 1 is ' Black'\n"
     ]
    }
   ],
   "source": [
    "possible_set = set(your_data_df[sensitive_field].unique())\n",
    "\n",
    "\n",
    "print('unique values from the sensitive class:{}'.format(possible_set))\n",
    "print('Please enter two different classes in the sensisitve field: ')\n",
    "\n",
    "input_str = 'Enter class 0:'\n",
    "warn_str = 'Please enter a valid class within sensitive field'\n",
    "result_str = \"Your sensitive attribute class 0 is \"\n",
    "sensitive_class0 = input_from_user(input_str, warn_str, result_str, possible_set)\n",
    "\n",
    "possible_set.remove(sensitive_class0)\n",
    "\n",
    "input_str = 'Enter class 1:'\n",
    "warn_str = 'Please enter a valid class within sensitive field'\n",
    "result_str = \"Your sensitive attribute class 1 is \"\n",
    "sensitive_class1 = input_from_user(input_str, warn_str, result_str, possible_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to omit any column from your data? Please enter Y or N:Y\n"
     ]
    }
   ],
   "source": [
    "# TODO: use 'input_from_user'\n",
    "valid_input = False\n",
    "while valid_input == False:\n",
    "    answer = input('Do you want to omit any column from your data? Please enter Y or N:')\n",
    "    if answer not in ['Y','N']:\n",
    "        print('Please enter Y or N')\n",
    "    else:\n",
    "        valid_input = True\n",
    "\n",
    "fields_to_delete = answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_can_omitted = set(all_columns)\n",
    "columns_can_omitted.remove(output_field)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a column, you want to omit or enter \"no more\" if you are done: Male\n",
      "Enter a column, you want to omit or enter \"no more\" if you are done:no more\n",
      "Columns to be omitted: [' Male']\n"
     ]
    }
   ],
   "source": [
    "if fields_to_delete == 'Y':\n",
    "    \n",
    "    not_to_consider_fields = []\n",
    "    valid_input = False\n",
    "    no_more = False\n",
    "\n",
    "\n",
    "    while (valid_input == False) or (no_more == False):\n",
    "        answer = input('Enter a column, you want to omit or enter \"no more\" if you are done:')\n",
    "\n",
    "\n",
    "        if answer == 'no more':\n",
    "            valid_input = True\n",
    "            no_more = True\n",
    "        else:\n",
    "            if answer not in columns_can_omitted:\n",
    "                print('Not a valid column')\n",
    "                #answer = input('Enter a column, you want to omit or enter \"no more\" if you are done:')\n",
    "            else:\n",
    "                valid_input = True\n",
    "                #no_more = False\n",
    "                not_to_consider_field = answer\n",
    "                not_to_consider_fields.append(not_to_consider_field) \n",
    "                \n",
    "    print('Columns to be omitted: {}'.format(not_to_consider_fields))\n",
    "else:\n",
    "    print('All columns are kept.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30939, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def processing_data_frame(output_field, sensitive_field, your_data_df, not_to_consider_fields,class0,class1):\n",
    "    \n",
    "    #drop columns\n",
    "    for item in not_to_consider_fields:\n",
    "        if item != sensitive_field:\n",
    "            your_data_df = your_data_df.drop(item, axis=1)\n",
    "            #print(item,'----',sensitive_field)\n",
    "           # print(item,your_data_df.columns)\n",
    "    \n",
    "    #check for missing values, do sth with them\n",
    "    your_data_df = your_data_df.dropna()\n",
    "    \n",
    "    # only keep the row with sensitive field equal to class1, and class2\n",
    "    your_data_df = your_data_df.loc[lambda df: df[sensitive_field].isin([class0, class1])]\n",
    "\n",
    "    #create Y\n",
    "    Y_df = your_data_df[output_field]\n",
    "    \n",
    "    #create Z\n",
    "    Z_df = your_data_df[sensitive_field]\n",
    "    \n",
    "    #create X\n",
    "    X_df = your_data_df.copy()\n",
    "    #print(X_df.shape)\n",
    "    X_df = X_df.drop(output_field, axis=1)\n",
    "    #print(X_df.shape)\n",
    "\n",
    "\n",
    "    if sensitive_field in not_to_consider_fields:\n",
    "        X_df = X_df.drop(sensitive_field, axis=1)\n",
    "        \n",
    "       \n",
    "    \n",
    "    return X_df, Y_df, Z_df\n",
    "    \n",
    "X_df, Y_df, Z_df = processing_data_frame(output_field, sensitive_field, your_data_df, not_to_consider_fields,sensitive_class0,sensitive_class1)    \n",
    " \n",
    "\n",
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output field: <=50K\n",
      "output field: <=50K Label 0-1  <=50K,  >50K\n",
      "sensitive field: White Class 0-1  White,  Black\n",
      "not to consider fields [' Male']\n"
     ]
    }
   ],
   "source": [
    "print('output field:{}'.format(output_field))\n",
    "print('output field:{} Label 0-1 {}, {}'.format(output_field,output_label0,output_label1 ))\n",
    "print('sensitive field:{} Class 0-1 {}, {}'.format(sensitive_field,sensitive_class0,sensitive_class1 ))\n",
    "print('not to consider fields',not_to_consider_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's see how biased your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_rule_for_Y1 48.42\n"
     ]
    }
   ],
   "source": [
    "def bias_checker_p_rule(Z_df, Y_df, class0, class1, label0, label1):\n",
    "    \n",
    "    \n",
    "    Y_df_Z_class0 = Y_df.loc[Z_df == class0]\n",
    "    Y0_df_Z_class0 = Y_df_Z_class0.loc[Y_df_Z_class0 == label0]\n",
    "    Y1_df_Z_class0 = Y_df_Z_class0.loc[Y_df_Z_class0 == label1]\n",
    "\n",
    "    Y_df_Z_class1 = Y_df.loc[Z_df == class1]\n",
    "    Y0_df_Z_class1 = Y_df_Z_class1.loc[Y_df_Z_class1 == label0]\n",
    "    Y1_df_Z_class1 = Y_df_Z_class1.loc[Y_df_Z_class1 == label1]\n",
    "    \n",
    "    Y0Z0 = (Y0_df_Z_class0.shape[0])\n",
    "    Y1Z0 = (Y1_df_Z_class0.shape[0])\n",
    "    Z0 = Y0Z0 + Y1Z0\n",
    "    #print('Z0:',Z0)\n",
    "    \n",
    "    Y0Z1 = (Y0_df_Z_class1.shape[0])\n",
    "    Y1Z1 = (Y1_df_Z_class1.shape[0])\n",
    "    Z1 = Y0Z1 + Y1Z1\n",
    "    #print('Z1:',Z1)\n",
    "    \n",
    "    \n",
    "    \"\"\" \n",
    "    print('Y0Z0',Y0_df_Z_class0.shape[0])\n",
    "    print('Y1Z0',Y1_df_Z_class0.shape[0])\n",
    "    print('Y0Z1',Y0_df_Z_class1.shape[0])\n",
    "    print('Y1Z1',Y1_df_Z_class1.shape[0])\n",
    "    \"\"\"\n",
    "    \n",
    "    p_rule_for_Y0 = format(100*min([(Y0Z1/Z1)/(Y0Z0/Z0),(Y0Z0/Z0)/(Y0Z1/Z1)]),'.2f')\n",
    "    p_rule_for_Y1 = format(100*min([(Y1Z1/Z1)/(Y1Z0/Z0),(Y1Z0/Z0)/(Y1Z1/Z1)]),'.2f')\n",
    "\n",
    "    \n",
    "    return p_rule_for_Y0,p_rule_for_Y1\n",
    "    \n",
    "p_rule_for_Y0,p_rule_for_Y1 = bias_checker_p_rule(Z_df, Y_df, sensitive_class0, sensitive_class1, output_label0, output_label1)   \n",
    "    \n",
    "print('p_rule_for_Y1',p_rule_for_Y1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforcing_binary_output_sensitive(Y_df,output_field,output_label0, output_label1,Z_df,sensitive_field,sensitive_class0, sensitive_class1):\n",
    "\n",
    "    Ybin = (Y_df == output_label1).astype(int)\n",
    "    Zbin = (Z_df == sensitive_class1).astype(int)\n",
    "\n",
    "\n",
    "    return Ybin, Zbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ybin, Zbin = enforcing_binary_output_sensitive(Y_df,output_field,output_label0, output_label1,Z_df,sensitive_field,sensitive_class0,sensitive_class1)\n",
    "\n",
    "#p_rule_for_Y0,p_rule_for_Y1 = bias_checker_p_rule(Zbin, Ybin, 0, 1, 0, 1)   \n",
    "\n",
    "#print('p_rule_for_Y1',p_rule_for_Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X_df,drop_first=True) \n",
    "Y = Ybin \n",
    "Z = Zbin\n",
    "test_train_ratio = 0.5\n",
    "\n",
    "#TODO: Can I do this in Keras?\n",
    "# TODO : what should be left to the user\n",
    "\n",
    "# split into train/test set\n",
    "X_train, X_test, y_train, y_test, Z_train, Z_test = train_test_split(X, Y, Z, test_size=test_train_ratio, \n",
    "                                                                     stratify=Y, random_state=7)\n",
    "\n",
    "# standardize the data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "scale_df = lambda df, scaler: pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)\n",
    "X_train = X_train.pipe(scale_df, scaler) \n",
    "X_test = X_test.pipe(scale_df, scaler) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_classifier(n_features):\n",
    "    inputs = Input(shape=(n_features,))\n",
    "    dense1 = Dense(32, activation='relu')(inputs)\n",
    "    dropout1 = Dropout(0.2)(dense1)\n",
    "    dense2 = Dense(32, activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.2)(dense2)\n",
    "    dense3 = Dense(32, activation=\"relu\")(dropout2)\n",
    "    dropout3 = Dropout(0.2)(dense3)\n",
    "    outputs = Dense(1, activation='sigmoid')(dropout3)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise NeuralNet Classifier\n",
    "main_task_ori = nn_classifier(n_features=X_train.shape[1])\n",
    "\n",
    "# train on train set\n",
    "history = main_task_ori.fit(X_train.values, y_train.values, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15470,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_task_ori.predict(X_test).ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "y_pred = main_task_ori.predict(X_test).ravel()#, index=y_test.index\n",
    "y_hat = (y_pred>0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_task_performance(X_test,y_test,y_hat):\n",
    "\n",
    "    main_task_accuracy = accuracy_score(y_test, y_hat)\n",
    "    return main_task_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.59\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d5f116443bdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmain_task_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.2f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp_rule_for_Y0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_rule_for_Y1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbias_checker_p_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p_rule_for_Y1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_rule_for_Y1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9f9c3de3a4ac>\u001b[0m in \u001b[0;36mbias_checker_p_rule\u001b[0;34m(Z_df, Y_df, class0, class1, label0, label1)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mY_df_Z_class0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mZ_df\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclass0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mY0_df_Z_class0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_df_Z_class0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_df_Z_class0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mY1_df_Z_class0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_df_Z_class0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_df_Z_class0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "main_task_accuracy = main_task_performance(X_test,y_test,y_hat)    \n",
    "print('Accuracy: {}'.format(format(100*main_task_accuracy,'.2f')))\n",
    "\n",
    "p_rule_for_Y0,p_rule_for_Y1 = bias_checker_p_rule(Z_test, y_hat, 0, 1, 0, 1)   \n",
    "\n",
    "print('p_rule_for_Y1',p_rule_for_Y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding adversarial net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE\n",
    "def p_rule(y_pred, z_values, threshold=0.5):\n",
    "    y_z_1 = y_pred[z_values == 1] > threshold if threshold else y_pred[z_values == 1]\n",
    "    y_z_0 = y_pred[z_values == 0] > threshold if threshold else y_pred[z_values == 0]\n",
    "    odds = y_z_1.mean() / y_z_0.mean()\n",
    "    return np.min([odds, 1/odds]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE\n",
    "def plot_distributions(y, Z, iteration=None, val_metrics=None, p_rules=None, fname=None):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(10, 4), sharey=True)\n",
    "    \n",
    "    legend=[sensitive_class0,sensitive_class1]\n",
    "    for idx in range(len(Z)):\n",
    "        for attr_val in [0, 1]:\n",
    "            ax = sns.distplot(y[Z == attr_val], hist=False, \n",
    "                              kde_kws={'shade': True,},\n",
    "                              label='{}'.format(legend[attr_val]))#, \n",
    "                              #ax=axes[idx])\n",
    "        ax.set_xlim(0,1)\n",
    "        ax.set_ylim(0,7)\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(\"sensitive attibute: {}\".format(sensitive_field))\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel('prediction distribution')\n",
    "        ax.set_xlabel(r'$P({{income>50K}}|z_{{{}}})$'.format(sensitive_field))\n",
    "    if iteration:\n",
    "        fig.text(1.0, 0.9, f\"Training iteration #{iteration}\", fontsize='16')\n",
    "    if val_metrics is not None:\n",
    "        fig.text(1.0, 0.65, '\\n'.join([\"Prediction performance:\",\n",
    "                                       f\"- ROC AUC: {val_metrics['ROC AUC']:.2f}\",\n",
    "                                       f\"- Accuracy: {val_metrics['Accuracy']:.1f}\"]),\n",
    "                 fontsize='16')\n",
    "    if p_rules is not None:\n",
    "        fig.text(1.0, 0.4, '\\n'.join([\"Satisfied p%-rules:\"] +\n",
    "                                     [f\"- {attr}: {p_rules[attr]:.0f}%-rule\" \n",
    "                                      for attr in p_rules.keys()]), \n",
    "                 fontsize='16')\n",
    "    fig.tight_layout()\n",
    "    if fname is not None:\n",
    "        plt.savefig(fname, bbox_inches='tight')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE\n",
    "\n",
    "class FairClassifier(object):\n",
    "    \n",
    "    def __init__(self, n_features, n_sensitive, tradeoff_lambda):\n",
    "        self.tradeoff_lambda = tradeoff_lambda\n",
    "        \n",
    "        clf_inputs = Input(shape=(n_features,))\n",
    "        adv_inputs = Input(shape=(1,))\n",
    "        \n",
    "        clf_net = self._create_clf_net(clf_inputs)\n",
    "        adv_net = self._create_adv_net(adv_inputs, n_sensitive)\n",
    "        self._trainable_clf_net = self._make_trainable(clf_net)\n",
    "        self._trainable_adv_net = self._make_trainable(adv_net)\n",
    "        self._clf = self._compile_clf(clf_net)\n",
    "        self._clf_w_adv = self._compile_clf_w_adv(clf_inputs, clf_net, adv_net)\n",
    "        self._adv = self._compile_adv(clf_inputs, clf_net, adv_net, n_sensitive)\n",
    "        self._val_metrics = None\n",
    "        self._fairness_metrics = None\n",
    "        \n",
    "        self.predict = self._clf.predict\n",
    "        \n",
    "    def _make_trainable(self, net):\n",
    "        def make_trainable(flag):\n",
    "            net.trainable = flag\n",
    "            for layer in net.layers:\n",
    "                layer.trainable = flag\n",
    "        return make_trainable\n",
    "        \n",
    "    def _create_clf_net(self, inputs):\n",
    "        dense1 = Dense(32, activation='relu')(inputs)\n",
    "        dropout1 = Dropout(0.2)(dense1)\n",
    "        dense2 = Dense(32, activation='relu')(dropout1)\n",
    "        dropout2 = Dropout(0.2)(dense2)\n",
    "        dense3 = Dense(32, activation='relu')(dropout2)\n",
    "        dropout3 = Dropout(0.2)(dense3)\n",
    "        outputs = Dense(1, activation='sigmoid', name='y')(dropout3)\n",
    "        return Model(inputs=[inputs], outputs=[outputs])\n",
    "        \n",
    "    def _create_adv_net(self, inputs, n_sensitive):\n",
    "        dense1 = Dense(32, activation='relu')(inputs)\n",
    "        dense2 = Dense(32, activation='relu')(dense1)\n",
    "        dense3 = Dense(32, activation='relu')(dense2)\n",
    "        outputs = [Dense(1, activation='sigmoid')(dense3) for _ in range(n_sensitive)]\n",
    "        return Model(inputs=[inputs], outputs=outputs)\n",
    "\n",
    "    def _compile_clf(self, clf_net):\n",
    "        clf = clf_net\n",
    "        self._trainable_clf_net(True)\n",
    "        clf.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return clf\n",
    "        \n",
    "    def _compile_clf_w_adv(self, inputs, clf_net, adv_net):\n",
    "        \"\"\"print('bu1')\n",
    "        print(type(inputs))\n",
    "        print(type(clf_net(inputs)))\n",
    "        print(type([clf_net(inputs)]))\n",
    "        print(type(adv_net(clf_net(inputs))))\n",
    "        print(type([adv_net(clf_net(inputs))]))\n",
    "        \"\"\"\n",
    "        clf_w_adv = Model(inputs=[inputs], outputs=[clf_net(inputs)]+[adv_net(clf_net(inputs))])\n",
    "        \n",
    "        self._trainable_clf_net(True)\n",
    "        self._trainable_adv_net(False)\n",
    "        loss_weights = [1.]+[-self.tradeoff_lambda]\n",
    "        \n",
    "        clf_w_adv.compile(loss=['binary_crossentropy']*(len(loss_weights)), \n",
    "                          loss_weights=loss_weights,\n",
    "                          optimizer='adam')\n",
    "        return clf_w_adv\n",
    "\n",
    "    def _compile_adv(self, inputs, clf_net, adv_net, n_sensitive):\n",
    "        adv = Model(inputs=[inputs], outputs=adv_net(clf_net(inputs)))\n",
    "        self._trainable_clf_net(False)\n",
    "        self._trainable_adv_net(True)\n",
    "        adv.compile(loss=['binary_crossentropy']*n_sensitive, optimizer='adam')\n",
    "        return adv\n",
    "\n",
    "    def _compute_class_weights(self, data_set):\n",
    "        class_values = [0, 1]\n",
    "        class_weights = []\n",
    "        \n",
    "        \"\"\"\n",
    "        balanced_weights = compute_class_weight('balanced', class_values, data_set)\n",
    "        class_weights.append(dict(zip(class_values, balanced_weights)))\n",
    "        \n",
    "        \"\"\"\n",
    "        if len(data_set.shape) == 1:\n",
    "            balanced_weights = compute_class_weight('balanced', class_values, data_set)\n",
    "            class_weights.append(dict(zip(class_values, balanced_weights)))\n",
    "        else:\n",
    "            n_attr =  data_set.shape[1]\n",
    "            for attr_idx in range(n_attr):\n",
    "                balanced_weights = compute_class_weight('balanced', class_values,\n",
    "                                                        np.array(data_set)[:,attr_idx])\n",
    "                class_weights.append(dict(zip(class_values, balanced_weights)))\n",
    "              \n",
    "                \n",
    "        return class_weights\n",
    "    \n",
    "    def _compute_target_class_weights(self, y):\n",
    "        class_values  = [0,1]\n",
    "        balanced_weights =  compute_class_weight('balanced', class_values, y)\n",
    "        class_weights = {'y': dict(zip(class_values, balanced_weights))}\n",
    "        \n",
    "        return class_weights\n",
    "        \n",
    "    def pretrain(self, x, y, z, epochs=10, verbose=0):\n",
    "        self._trainable_clf_net(True)\n",
    "        self._clf.fit(x.values, y.values, epochs=epochs, verbose=verbose)\n",
    "        self._trainable_clf_net(False)\n",
    "        self._trainable_adv_net(True)\n",
    "        class_weight_adv = self._compute_class_weights(z)\n",
    "        self._adv.fit(x.values, z.values, class_weight=class_weight_adv, \n",
    "                      epochs=epochs, verbose=verbose)\n",
    "        \n",
    "    def fit(self, x, y, z, validation_data=None, T_iter=250, batch_size=128,\n",
    "            save_figs=False):\n",
    "        \n",
    "        n_sensitive = 1\n",
    "        if validation_data is not None:\n",
    "            x_val, y_val, z_val = validation_data\n",
    "\n",
    "        class_weight_adv = self._compute_class_weights(z)\n",
    "        class_weight_clf_w_adv = [{0:1., 1:1.}]+class_weight_adv\n",
    "        \n",
    "        self._val_metrics = pd.DataFrame()\n",
    "        self._fairness_metrics = [] #pd.DataFrame()  \n",
    "        \n",
    "        for idx in range(T_iter):\n",
    "            #print(idx)\n",
    "            if validation_data is not None:\n",
    "                y_pred = pd.Series(self._clf.predict(x_val).ravel(), index=y_val.index)\n",
    "                self._val_metrics.loc[idx, 'ROC AUC'] = roc_auc_score(y_val, y_pred)\n",
    "                self._val_metrics.loc[idx, 'Accuracy'] = (accuracy_score(y_val, (y_pred>0.5))*100)\n",
    "                \n",
    "               \n",
    "                self._fairness_metrics.append(p_rule(y_pred,z_val))\n",
    "                \n",
    "                display.clear_output(wait=True)\n",
    "                #print(type(y_pred))\n",
    "                #print(type(z_val))\n",
    "                plot_distributions(y_pred, z_val, idx+1, self._val_metrics.loc[idx],\n",
    "                                   self._fairness_metrics[idx], \n",
    "                                   fname=f'output/{idx+1:08d}.png' if save_figs else None)\n",
    "                plt.show(plt.gcf())\n",
    "            \n",
    "            # train adverserial\n",
    "            self._trainable_clf_net(False)\n",
    "            self._trainable_adv_net(True)\n",
    "            self._adv.fit(x.values, z.values, batch_size=batch_size, \n",
    "                          class_weight=class_weight_adv, epochs=1, verbose=0)\n",
    "            \n",
    "            # train classifier\n",
    "            self._trainable_clf_net(True)\n",
    "            self._trainable_adv_net(False)\n",
    "            indices = np.random.permutation(len(x))[:batch_size]\n",
    "            #self._clf_w_adv.train_on_batch(x.values[indices], \n",
    "                                           #[y.values[indices]]+[z.values[indices]])\n",
    "            self._clf_w_adv.train_on_batch(x.values[indices], \n",
    "                                           [y.values[indices]]+[z.values[indices]],\n",
    "                                           class_weight=class_weight_clf_w_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradeoff_lambda = 130.\n",
    "\n",
    "#lambda_race=130\n",
    "#lambda_sex=30\n",
    "# initialise FairClassifier\n",
    "clf = FairClassifier(n_features=X_train.shape[1], n_sensitive=1,\n",
    "                     tradeoff_lambda=tradeoff_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bu0)\n",
    "# pre-train both adverserial and classifier networks\n",
    "clf.pretrain(X_train, y_train, Z_train, verbose=0, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adverserial train on train set and validate on test set\n",
    "clf.fit(X_train, y_train, Z_train, \n",
    "        validation_data=(X_test, y_test, Z_test),\n",
    "        T_iter=165, save_figs=create_gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# predict on test set\n",
    "y_pred = pd.Series(clf.predict(X_test).ravel(), index=y_test.index)\n",
    "y_hat = (y_pred>0.5)*1\n",
    "\n",
    "main_task_accuracy = main_task_performance(X_test,y_test,y_hat)    \n",
    "print('Accuracy: {}'.format(format(100*main_task_accuracy,'.2f')))\n",
    "\n",
    "p_rule_for_Y0,p_rule_for_Y1 = bias_checker_p_rule(Z_test, y_hat, 0, 1, 0, 1)   \n",
    "\n",
    "print('p_rule_for_Y0',p_rule_for_Y0)\n",
    "print('p_rule_for_Y1',p_rule_for_Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[Z_test == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
